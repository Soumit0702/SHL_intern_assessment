{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":97919,"databundleVersionId":11872932,"sourceType":"competition"},{"sourceId":11657687,"sourceType":"datasetVersion","datasetId":7315721}],"dockerImageVersionId":31013,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install language_tool_python","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport librosa\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm \nfrom transformers import pipeline\nimport language_tool_python\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom scipy.stats import pearsonr\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Update JAVA version","metadata":{}},{"cell_type":"code","source":"!apt-get install -y openjdk-17-jdk\n!update-alternatives --set java /usr/lib/jvm/java-17-openjdk-amd64/bin/java\n\n!java -version\n\n!pip install --upgrade language-tool-python","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Device assignment","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Data Loading\ntrain_df = pd.read_csv('/kaggle/input/shl-intern-hiring-assessment/Dataset/train.csv')\ntest_df = pd.read_csv('/kaggle/input/shl-intern-hiring-assessment/Dataset/test.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Extract Audio Features Function","metadata":{}},{"cell_type":"code","source":"# Feature Extraction Functions\ndef extract_audio_features(file_path):\n    y, sr = librosa.load(file_path, sr=16000)\n    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n    contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n    return np.concatenate([np.mean(mfcc, axis=1), \n                          np.mean(chroma, axis=1), \n                          np.mean(contrast, axis=1)])\n\nasr_pipe = pipeline(\"automatic-speech-recognition\", \n                   model=\"openai/whisper-medium\",\n                   device=0 if torch.cuda.is_available() else -1,\n                   return_timestamps=True)\n\ntool = language_tool_python.LanguageTool('en-US')\n\ndef process_text_features(text):\n    matches = tool.check(text)\n    error_count = len(matches)\n    error_types = len({m.ruleId for m in matches})\n    word_count = len(text.split())\n    return np.array([error_count, error_types, word_count])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Preprocess Data Function","metadata":{}},{"cell_type":"code","source":"# Data Preprocessing\ndef preprocess_data(df, is_train=True, num_samples=None):\n    features = []\n    labels = [] if is_train else None\n    \n    for idx, row in tqdm(df.iterrows()):\n        if is_train:\n            file_path = '/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/train/' + row[\"filename\"]\n        else:\n            file_path = '/kaggle/input/shl-intern-hiring-assessment/Dataset/audios/test/' + row[\"filename\"]  \n        \n        audio_feat = extract_audio_features(file_path)\n        text = asr_pipe(file_path)[\"text\"]\n        text_feat = process_text_features(text)\n        combined_feat = np.concatenate([audio_feat, text_feat])\n        features.append(combined_feat)\n        \n        if is_train:\n            labels.append(row['label'])\n    \n    return (np.array(features), np.array(labels)) if is_train else np.array(features)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Spliting Training and Validation","metadata":{}},{"cell_type":"code","source":"X_train, y_train = preprocess_data(train_df, num_samples=300)\n\n# Split for validation\nX_train_full, X_val, y_train_full, y_val = train_test_split(\n    X_train, y_train, test_size=0.2, random_state=42\n)\n\n# Feature scaling\naudio_scaler = StandardScaler().fit(X_train_full[:, :59])\ntext_scaler = StandardScaler().fit(X_train_full[:, 59:])\n\ndef scale_features(features):\n    audio = audio_scaler.transform(features[:, :59])\n    text = text_scaler.transform(features[:, 59:])\n    return np.concatenate([audio, text], axis=1)\n\nX_train_scaled = scale_features(X_train_full)\nX_val_scaled = scale_features(X_val)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# np.save('/kaggle/output/train__x', X_train)\n# np.save(\"'/kaggle/output/train__x', X_train\")\n# np.save('/kaggle/output/train__y', y_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Dataset and DataLoader","metadata":{}},{"cell_type":"code","source":"# Dataset and DataLoader\nclass GrammarDataset(Dataset):\n    def __init__(self, features, labels):\n        self.features = features\n        self.labels = labels\n        \n    def __len__(self):\n        return len(self.labels)\n    \n    def __getitem__(self, idx):\n        return (torch.tensor(self.features[idx], dtype=torch.float32),\n                torch.tensor(self.labels[idx], dtype=torch.float32))\n\ntrain_dataset = GrammarDataset(X_train_scaled, y_train_full)\nval_dataset = GrammarDataset(X_val_scaled, y_val)\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":" # Model Architecture\nclass GrammarModel(nn.Module):\n    def __init__(self, input_size):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(input_size, 128),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Linear(64, 1)\n        )\n    def forward(self, x):\n        return self.net(x).squeeze()\n\nmodel = GrammarModel(X_train_scaled.shape[1]).to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.MSELoss()\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.2, patience=5)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"# Training with Early Stopping\nbest_loss = float('inf')\npatience = 10\nno_improve = 0\ntrain_losses = []\nval_losses = []\n\nfor epoch in range(100):\n    # Training\n    model.train()\n    epoch_loss = 0\n    for inputs, targets in train_loader:\n        inputs, targets = inputs.to(device), targets.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n        \n        epoch_loss += loss.item() * inputs.size(0)\n    train_loss = epoch_loss / len(train_loader.dataset)\n    train_losses.append(train_loss)\n    \n    # Validation\n    model.eval()\n    val_loss = 0\n    with torch.no_grad():\n        for inputs, targets in val_loader:\n            inputs, targets = inputs.to(device), targets.to(device)\n            outputs = model(inputs)\n            val_loss += criterion(outputs, targets).item() * inputs.size(0)\n    val_loss /= len(val_loader.dataset)\n    val_losses.append(val_loss)\n    \n    # Update scheduler\n    scheduler.step(val_loss)\n    \n    # Early stopping\n    if val_loss < best_loss:\n        best_loss = val_loss\n        no_improve = 0\n        torch.save(model.state_dict(), 'best_model.pth')\n    else:\n        no_improve += 1\n        \n    print(f'Epoch {epoch+1:03d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n    \n    if no_improve >= patience:\n        print(f'Early stopping at epoch {epoch+1}')\n        break\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Evaluation Metrics along with graphs loss curves and prediction distribution","metadata":{}},{"cell_type":"code","source":"# Training Evaluation\nmodel.load_state_dict(torch.load('best_model.pth'))\nmodel.eval()\nwith torch.no_grad():\n    y_pred = model(torch.tensor(scale_features(X_train), dtype=torch.float32).to(device)).cpu().numpy()\n\nrmse = np.sqrt(mean_squared_error(y_train, y_pred))\nmae = mean_absolute_error(y_train, y_pred)\nr2 = r2_score(y_train, y_pred)\npearson, _ = pearsonr(y_train, y_pred)\n\nprint(f'Training Metrics:')\nprint(f'RMSE: {rmse:.4f}')\nprint(f'MAE: {mae:.4f}')\nprint(f'R²: {r2:.4f}')\nprint(f'Pearson: {pearson:.4f}')\n\n# 10. Visualization\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(train_losses, label='Train Loss')\nplt.plot(val_losses, label='Val Loss')\nplt.legend()\nplt.title('Loss Curves')\n\nplt.subplot(1, 2, 2)\nplt.scatter(y_train, y_pred, alpha=0.5)\nplt.plot([0,5], [0,5], 'r--')\nplt.xlabel('True Scores')\nplt.ylabel('Predicted Scores')\nplt.title('Prediction Distribution')\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Test Prediction","metadata":{}},{"cell_type":"code","source":"# Test Prediction\n# Preprocess test data\nX_test = preprocess_data(test_df, is_train=False)\nX_test_scaled = scale_features(X_test)\n\n# Predict\nmodel.eval()\nwith torch.no_grad():\n    test_pred = model(torch.tensor(X_test_scaled, dtype=torch.float32).to(device)).cpu().numpy()\n\n# Generate submission\nsubmission_df = pd.DataFrame({\n    'filename': test_df['filename'].values,\n    'label': np.clip(test_pred, 0, 5)  # Constrain scores between 0-5\n})\n\nsubmission_df.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}